---
title: "Weather&Accidents"
author: "Kobi Ocran"
date: "9/20/2020"
output: html_document
---

```{r}
### download necessary packages

library(dplyr)

library(ggplot2)

library(stringr)

library(nnet)# for Multinomial Logistic Regression

#library(rms)

library(MASS)

```

```{r}
# setwd("~/Desktop/DASem/Weather-Accidents")

# USaccidents <-  read.csv("US_Accidents_June20.csv") #read in the US accidents dataset


#saveRDS(USaccidents, file = "~/Desktop/DASem/Weather-Accidents/USaccidents.RDS") #save the large dataset in an RDS file

USaccidents <- readRDS("~/Desktop/DASem/Weather-Accidents/USaccidents.RDS") #open the RDS files (dataset)


```


```{r}

# Data Cleaning and Variable Conversion 

USaccidents$Severity <- as.factor(USaccidents$Severity) # convert Severity from int to factor(1,2,3,4)

#USaccidents$Humidity... <- as.numeric((USaccidents$Humidity...)/100) # convert from percent to numeric (only run once!)

# identify nas in dataframe  

na_count <- sapply(USaccidents, function(y) sum(length(which(is.na(y)))))


# sum(USaccidents$Weather_Timestamp == "") Weather_timestamp has 43325 empty observations 

# USaccidents <- USaccidents %>%
#   filter(Weather_Timestamp != "")  #exclude empty Weather_Timestamp observations.

USaccidents$Date <- format(as.Date(USaccidents$End_Time, "%Y-%m-%d"), "%Y-%m-%d") #convert DateTime to Date

USaccidents$Year <- format(as.Date(USaccidents$End_Time, format = "%Y-%m-%d"), "%Y") #extract the year only (The master dataset does not seem to have data for 2018 - possible limitation)

na_count1 <- sapply(USaccidents, function(y) sum(length(which(is.na(y)))))

# explore distribution of variables,  helps identify outliers , helps to see if they follow a normal distribution 


#create a function to display histogram for independent variables

library(ggplot2)

create_hist = function(variable, colour,my_title){ 
  USaccidents %>% 
  ggplot(aes(x = variable)) +
  geom_histogram(bins = 30, fill = colour) + 
  labs(title = as.character(my_title)) + # try to add variable as part of title 
  theme(plot.title = element_text(hjust = 0.5))
}

```


```{r}
# visibility 

vis <- create_hist(USaccidents$Visibility.mi., 'blue', "Histogram of Visibility")

vis

```


```{r}
summary(USaccidents$Visibility.mi.)
```


```{r}
# precipitation 

precip <- create_hist(USaccidents$Precipitation.in., 'red', "Histogram of Precipation")

precip 
```


```{r}
summary(USaccidents$Precipitation.in.)

precip_nas <- (2025881 / nrow(USaccidents)) * 100 #percentage of nas

precip_zeros <- (1238498 / nrow(USaccidents)) * 100 # percentage of zeros

precip_nas + precip_zeros 

```


```{r}
# wind speed 

speed <- create_hist(USaccidents$Wind_Speed.mph., 'green', 'Histogram of Wind Speed')

speed
```


```{r}
summary(USaccidents$Wind_Speed.mph.)
```

```{r}
# pressure 
press <- create_hist(USaccidents$Pressure.in., 'orange', 'Histogram of Pressure')

press
```

```{r}
summary(USaccidents$Pressure.in.) 
```

```{r}
# Wind_Chill 

chill <- create_hist(USaccidents$Wind_Chill.F., 'salmon2', 'Histogram of Wind Chill')

chill

#exclude rows with a missing value for  Wind_Chill

USaccidents <- USaccidents %>%
  filter(is.na(Wind_Chill.F.)==F)

```


```{r}
summary(USaccidents$Wind_Chill.F.)


```

```{r}
# Temperature 

temp <- create_hist(USaccidents$Temperature.F., 'plum', 'Histogram of Temperature')

temp

```


```{r}
summary(USaccidents$Temperature.F)
```


```{r}
#Humidity 

humid <- create_hist(USaccidents$Humidity..., 'lightcoral' , 'Histogram of Humidity')

humid
```


```{r}
summary(USaccidents$Humidity...)
```

```{r}
### Let us make a grid of this histogram

library(gridExtra)

Predictors_data <- USaccidents %>%
  select(Precipitation.in., Visibility.mi., Temperature.F., Wind_Chill.F., Wind_Speed.mph.,
         Pressure.in., Humidity...) 

grid.arrange(
  ggplot(data = Predictors_data, aes(Precipitation.in.))+geom_histogram(bins = 30, fill = 'red') ,
  ggplot(data = Predictors_data, aes(Visibility.mi.))+geom_histogram(bins = 30, fill = 'blue'),
  ggplot(data = Predictors_data, aes(Temperature.F.))+geom_histogram(bins = 30, fill = 'plum'),
  ggplot(data = Predictors_data, aes(Wind_Chill.F.))+geom_histogram(bins = 30, fill = 'salmon2'),
  ggplot(data = Predictors_data, aes(Wind_Speed.mph.))+geom_histogram(bins = 30, fill = 'green'),
  ggplot(data = Predictors_data, aes(Pressure.in.))+geom_histogram(bins = 30, fill = 'orange'),
  ggplot(data = Predictors_data, aes(Humidity...))+geom_histogram(bins = 30, fill = 'lightcoral'),
   ncol=2)

```


```{r}

Midstates <- c("IL", "IN", "IA", "KS","MI", "MN", "MO", "NE", "ND", "OH", "SD", "WI") # identify the Midwestern states 

MWaccidents <- filter(USaccidents, State %in% Midstates) # filter the Midwestern states from the master dataset (USaccidents) and create a new dataset with only Midwest states 

# create to_csv for Tableau 

write.csv(MWaccidents, "~/Desktop/DASem/Weather-Accidents/MWaccidents.csv", row.names = FALSE)

#saveRDS(MWaccidents, file = "~/Desktop/DASem/Weather-Accidents/MWaccidents.RDS") #save the large dataset in an RDS file

MWaccidents <- readRDS("~/Desktop/DASem/Weather-Accidents/MWaccidents.RDS")
```

```{r}
# Let Severity be the Dependent Variable,

# Let visibility, precipitation, temperature, wind_chill, wind_speed, distance, pressure, weather condition (rain, snow, thunderstorm) and humidity. 

# Severity scales based on different sources. The cases should be separated by each source (MapQuest & Bing). 


MQ <- MWaccidents %>%
  filter(Source == "MapQuest")  #create a table to capture accident cases from the Mapquest source (995627 observations)

MQ_Bing <- MWaccidents %>%
  filter(Source == "MapQuest-Bing") #create a table to capture accident cases from the MapQuest - Bing source. Reported by both (indistinguishable and perhaps a possible limitation of the study)



saveRDS(MQ, file = "~/Desktop/DASem/Weather-Accidents/MQ.RDS") #save the large dataset in an RDS file

#MQ <- readRDS("~/Desktop/DASem/Weather-Accidents/MQ.RDS")

```

```{r}
# table under development 
d <- head(USaccidents[,1:2])

grid.table(d)
```


```{r}

# create dummy variables for each Weather_Condition (group them and classify) and for Twilight variables. Observation: A lot of confounding variables (under development )

# weather data for Mapquest
MQdata <- MQ %>%
  select(Severity, Visibility.mi., Temperature.F., Wind_Chill.F., Wind_Speed.mph.,
         Pressure.in.,Humidity...,Weather_Condition, Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight)

write.csv(MQdata, "~/Desktop/DASem/Weather-Accidents/MQdata.csv", row.names = FALSE)

#weather data for Mapquest_Bing
MQ_Bingdata <- MQ_Bing %>%
  select(Severity, Visibility.mi. , Temperature.F., Wind_Chill.F., Wind_Speed.mph.,
         Pressure.in.,Weather_Condition, Humidity..., Sunrise_Sunset, Civil_Twilight, Nautical_Twilight, Astronomical_Twilight)

saveRDS(MQdata, file = "~/Desktop/DASem/Weather-Accidents/MQdata.RDS") #save the large dataset in an RDS file

#MQdata <- readRDS("~/Desktop/DASem/Weather-Accidents/MQdata.RDS")


library(ggfortify)

# Correlation plots

corplot <- autoplot(cor(MQdata[,2:7], use="pairwise.complete.obs"), , main = "Correlation Plot for Weather Characteristics") # considering other ways to plot  
 
corplot + theme(axis.text.x = element_text(angle = 60, hjust = 1), plot.title = element_text(hjust = 0.5))

```



```{r}

#filter non-continous 

MQdata <- MQdata %>%
  select(-Weather_Condition, -Sunrise_Sunset, -Civil_Twilight, -Nautical_Twilight, -Astronomical_Twilight)


MQ_Bingdata<- MQ_Bingdata %>%
  select(-Weather_Condition, -Sunrise_Sunset, -Civil_Twilight, -Nautical_Twilight, -Astronomical_Twilight)
# Multinomial Logistic Regression analysis (Mapquestdata)

# Data Partition 

set.seed(222)

ind <- sample(2, nrow(MQdata),
              replace = TRUE,
              prob = c(0.6,0.4)) #60% / 40% data split 

trainMQ <- MQdata[ind == 1, ]

testMQ <- MQdata[ind == 2, ]


#trainMQ$Severity <- relevel(trainMQ$Severity, ref = "1") #pick a reference level



mymodel1 <- multinom(Severity ~ ., data = trainMQ) #exclude non-continuous variables 

summary(mymodel1)

```


The log odds

E.g For Humidity, The log odds that the accident instance is of category 2 compared to category 1 is negative. There is a negative impact on that. 


```{r}

# 2-tailed Z - test

z_test1 <- summary(mymodel1)$coefficients/summary(mymodel1)$standard.errors

p1 <- (1-pnorm(abs(z_test1),0, 1)) * 2

p1
```

The statistically significant variables: Precipitation.in., Pressure.in.

```{r}

### RUN EACH SEPERATELY TO OBTAIN RESULTS 

# Confusion Matrix & Misclassification Error - Training Data

pred_train <- predict(mymodel1, trainMQ)

table1 <- table(pred_train, trainMQ$Severity)

table1

#Accuracy Rate

accuracy1 <- sum(diag(table1))/sum(table1)

accuracy1

# Confusion Matrix & Misclassification Error - Test Data

pred_test <- predict(mymodel1, testMQ)

table2 <- table(pred_test, testMQ$Severity)

table2

accuracy2 <- sum(diag(table2))/sum(table2)

accuracy2

# Prediction and Model Assessment 

n1 <- table(trainMQ$Severity)

n1/sum(n1)

table1/colSums(table1)

table2/colSums(table2)


```

- Possible Limitations: Dominance of one class 



The statistically significant variables: Pressure.in. 


```{r}
# Ordnial Probit & Logit 


# I was going to perform a Multinomial Probit & Logit until the class imbalances were discovered
```



```{r}
# Logistic Regression Model 


# There is a huge class imbalance (1&2) will be classified as low levels of severity and (3&4) will be grouped as one class of high severity. We will dummy code the severity variable 

table(MQdata$Severity)

MQdata <- MQdata %>%
  mutate(Severity_1 = case_when(grepl('1|2',Severity) ~ 0, TRUE ~ 1)) # 1: 1.52 ratio 

MQdata$Severity_1 <- as.factor(MQdata$Severity_1)

na_count2 <- sapply(MQdata, function(y) sum(length(which(is.na(y)))))


reg1 <- glm(Severity_1 ~ Visibility.mi. + Temperature.F. + Wind_Chill.F. + Wind_Speed.mph. + Pressure.in. + Humidity... , data = MQdata , family = binomial('logit'), na.action = na.omit)

reg1

summary(reg1)


# Compare to orginial model without highly correlated variables (exclude Wind_Chill)

reg1a <- glm(Severity_1 ~ Visibility.mi. + Temperature.F.  + Wind_Speed.mph. + Pressure.in. + Humidity... , data = MQdata , family = binomial('logit'), na.action = na.omit)


summary(reg1a)

# Only include significant variables

reg1b <- glm(Severity_1 ~ Visibility.mi. + Pressure.in. + Humidity... , data = MQdata , family = binomial('logit'), na.action = na.omit)


summary(reg1b)



# Model Evaluation 
logLik(reg1)
logLik(reg1a)
logLik(reg1b)

# ODDS RATIO 





predicted1 <- as.numeric(predict.glm(reg1))

```




```{r}

# Let us consider the case for Ohio

# Let us identify the road types

# The use of "I", "Ave", "St", "Rd", "Dr", "Outerbelt", "Hwy", "State Route", "Pike", "Highway", "Innerbelt", "Blvd", "Expy", "MI-39 N"

OHaccidents <- filter(USaccidents, State == "OH") #filter accident cases in ohio

# Let us identify the road types ()

# E.g "I", "Ave", "St", "Rd", "Dr", "Outerbelt", "Hwy", "State Route", "Pike", "Highway", "Innerbelt", "Blvd", "Expy", "MI-39 N"

MWaccidents <- MWaccidents %>%
  mutate(Road_Type = case_when(grepl('I-|Hwy|State Route|Highway|Expy',Street) ~ 'High-Speed',grepl('Ave|St|Rd|Dr|Blvd',Street) ~ 'Local', TRUE ~ 'Other'))

MQdata <- MQdata %>%
  mutate(Road_Type = case_when(grepl('I-|Hwy|State Route|Highway|Expy',Street) ~ 'High-Speed',grepl('Ave|St|Rd|Dr|Blvd',Street) ~ 'Local', TRUE ~ 'Other'))


OHaccidents <- OHaccidents %>%
  mutate(Road_Type = case_when(grepl('I-|Hwy|State Route|Highway|Expy',Street) ~ 'High-Speed',grepl('Ave|St|Rd|Dr|Blvd',Street) ~ 'Local', TRUE ~ 'Other'))

# identify whether the accident instances happend on a high-speed road (highways, interstates and state roads) or local roads/ low speed (street, avenues, boulevards)

```

```{r}
# Let us explore the visibility levels for each road type

a <- OHaccidents %>%
  filter(is.na(Visibility.mi.) == FALSE) %>%
  select(Visibility.mi.,Road_Type) %>%
  group_by(Road_Type) %>%
  summarise(mean_visibility = mean(Visibility.mi.)) %>%
  ggplot(aes(Road_Type, mean_visibility, fill = Road_Type)) +
  geom_col()+
  labs(title = "Road Types & Visibility") + 
  theme(plot.title = element_text(hjust = 0.5))

a

```

- explore the corrleation using cor

```{r}
# Let us explore boxplots 

b <- MWaccidents %>%
  filter(is.na(Visibility.mi.) == FALSE) %>%
  select(Visibility.mi.,Road_Type) %>%
  ggplot(aes(Road_Type, Visibility.mi.)) +
  geom_boxplot(binaxis = "y", stackdir = "center", position = "dodge") +
  labs(title = "Boxplot : Road Type and Visibility in the Midwest")+
  theme(plot.title = (element_text(hjust=0.5)))

b
```



- Look a bit more closely when classying the streets into road types

- Maybe explore for specific states 

- 



```{r}
### Let us explore visibility patterns across a midwestern states (from 2016 to 2020)



c <- MWaccidents %>%
  filter(is.na(Visibility.mi.) == FALSE) %>% 
  select(Visibility.mi.,Weather_Timestamp, Year, State) %>%
  group_by(Year, State) %>%
  summarize(mean_visibility = mean(Visibility.mi.))
  


c %>% ggplot(aes(x = Year, y = mean_visibility, group = State)) +
  geom_line(size = 1, linetype = 1, aes(colour = State)) + 
  geom_point()
  
```

There seems to be some downward trends in visibility perhaps indicating that weather has gotten worse over the years. North Dakota only has data from 2019 to 2020. May consider filtering the state out.


```{r}
### Let us explore visibility patterns across a midwestern states (from 2016 to 2020)



c1 <- MWaccidents %>%
  filter(is.na(Visibility.mi.) == FALSE) %>% 
  filter(State == "SD" | State == "ND" ) %>%
  select(Visibility.mi.,Weather_Timestamp, Year, State) %>%
  group_by(Year, State) %>%
  summarise(mean_visibility = mean(Visibility.mi.))
  


c1 %>% ggplot(aes(x = Year, y = mean_visibility, group = State)) +
  geom_line(size = 1, linetype = 1, aes(colour = State)) + 
  geom_point()
```


```{r}
### Let us explore visibility patterns across a midwestern states (from 2016 to 2020)



c2 <- MWaccidents %>%
  filter(is.na(Visibility.mi.) == FALSE) %>% 
  filter(State != "SD" & State != "ND" ) %>%
  select(Visibility.mi.,Weather_Timestamp, Year, State) %>%
  group_by(Year, State) %>%
  summarise(mean_visibility = mean(Visibility.mi.))
  


c2 %>% ggplot(aes(x = Year, y = mean_visibility, group = State)) +
  geom_line(size = 1, linetype = 1, aes(colour = State)) + 
  geom_point() +
  labs(title = "Visibility over Time in The Midwest") + # try to add variable as part of title 
  theme(plot.title = element_text(hjust = 0.5))
  
  
```



```{r}
### Let us make a stacked bar graph with the frequency of accident cases and severity cats. with the road types 


stack1 <- MWaccidents %>%
  select(Road_Type, Severity)
  
ggplot(stack1, aes(x = Road_Type, fill = Severity)) +
  geom_bar() +
  labs(title = "Stacked barplot : Number of Instances for Each Severity per Road Type ") + 
  theme(plot.title = element_text(hjust = 0.5))

ggplot(stack1, aes(x = Severity, fill = Road_Type)) +
  geom_bar(position = position_dodge())


stack2 <- MQdata %>%
  select(Road_Type, Severity, Severity_1)

#under development 

ggplot(stack1, aes(x = Road_Type, fill = Severity_1)) +
  geom_bar() +
  labs(title = "Stacked barplot : Number of Instances for Each Severity per Road Type ") + 
  theme(plot.title = element_text(hjust = 0.5))


  
  
```
-  to be investigated


```{r}

library(MASS)

### Ordered Logit Model 

model.1 <- polr(Severity ~ Visibility.mi. + Temperature.F. + Wind_Chill.F. + Wind_Speed.mph. +
                          Pressure.in. + Humidity..., data = MQdata , na.action = na.omit, method = 'logistic') #omitting values in the regression Model

# model.1<-glm(Severity ~ Visibility.mi. + Temperature.F. + Wind_Chill.F. + Wind_Speed.mph. +
#                            Pressure.in. + Humidity...,data = MQdata, family = binomial)

print(model.1)


### Ordered Probit Model 

# summary(model.2 <- polr(Severity ~ Visibility.mi. + Temperature.F. + Wind_Chill.F. + Wind_Speed.mph. +
#                           Pressure.in. + Humidity..., data = MQdata , na.action = na.omit, method = 'probit' )) 

summary(model.2<-glm(Severity ~ Visibility.mi. + Temperature.F. + Wind_Chill.F. + Wind_Speed.mph. +
                           Pressure.in. + Humidity...,data = MQdata, family = binomial))


```


You would want a t value above 1.96 




```{r}

# Confidence Interval 

confint1 <- confint(model.1, level = .95)

#saveRDS(confint1, file = "~/Desktop/DASem/Weather-Accidents/confint1.RDS")

confint1 <- readRDS("~/Desktop/DASem/Weather-Accidents/confint1.RDS")

confin1



confint2 <- confint(model.2, level = .95)


#saveRDS(confint2, file = "~/Desktop/DASem/Weather-Accidents/confint1.RDS")



# Model Evaluation 

logLik(model.1)

```



















